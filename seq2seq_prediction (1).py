# -*- coding: utf-8 -*-
"""Seq2Seq_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x35YTbKVxqLZjsZXkpI46lhugiqVIDO6
"""

!pip install tensorflow

import tensorflow as tf

#Location of models
# model_location = '/content/drive/MyDrive/data sets/'

# "C:\Users\vemula suman\Downloads\translation\seq2seq_encoder_eng_hin.keras"

#Encoder model
encoder_model = tf.keras.models.load_model(r"C:\Users\vemula suman\Downloads\translation\seq2seq_encoder_eng_hin.keras")

#Decoder model
decoder_model = tf.keras.models.load_model(r'C:\Users\vemula suman\Downloads\translation\seq2seq_decoder_eng_hin.keras')

encoder_model.summary()

decoder_model.summary()

import pickle

encoder_t = pickle.load(open(r'C:\Users\vemula suman\Downloads\translation\encoder_tokenizer_eng.pickle','rb'))
decoder_t = pickle.load(open(r'C:\Users\vemula suman\Downloads\translation\decoder_tokenizer_hin.pickle','rb'))

max_encoder_seq_length = 22 #From the training
max_decoder_seq_length = 27 #From the training

#Build a dictionary - Key is word index and value is actual word. This will be useful in prediction
int_to_word_decoder = dict((i,c) for c, i in decoder_t.word_index.items())

#Verify dictionary
int_to_word_decoder

def encode_input(input_str):

    #Convert words to indexes
    encoder_seq = encoder_t.texts_to_sequences([input_str])

    #Pad sequences
    encoder_input_data = tf.keras.preprocessing.sequence.pad_sequences(encoder_seq,
                                                                       maxlen=max_encoder_seq_length,
                                                                       padding='post')
    return encoder_input_data

encode_input('I have a car')

import numpy as np

def decode_sentence(input_str):

    #Convert input string to padded sequence
    input_seq = encode_input(input_str)

    #Get the encoder state values
    decoder_initial_states_value = encoder_model.predict(input_seq)

    #Build a sequence with '<start>' - starting sequence for Decoder
    target_seq = np.zeros((1,1))
    target_seq[0][0] = decoder_t.word_index['<start>']

    #flag to check if prediction should be stopped
    stop_loop = False

    #Initialize predicted sentence
    predicted_sentence = ''

    #start the loop
    while not stop_loop:

        predicted_outputs, h, c = decoder_model.predict([target_seq] +
                                                        decoder_initial_states_value)

        #Get the predicted output with highest probability
        predicted_output = np.argmax(predicted_outputs[0,-1,:])

        #Get the predicted word from predicter integer
        predicted_word = int_to_word_decoder[predicted_output]

        #Check if prediction should stop
        if(predicted_word == '<end>' or len(predicted_sentence) > max_decoder_seq_length):

            stop_loop = True
            continue

        #Updated predicted sentence
        if (len(predicted_sentence) == 0):
            predicted_sentence = predicted_word
        else:
            predicted_sentence = predicted_sentence + ' ' + predicted_word

        #Update target_seq to be the predicted word index
        target_seq[0][0] = predicted_output

        #Update initial states value forr decoder
        decoder_initial_states_value = [h,c]


    return predicted_sentence

decode_sentence("I'm starving.")





